{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = './sample_data/Img/'\n",
    "annotation_file = './sample_data/Anno/'\n",
    "export_file = './export'\n",
    "\n",
    "identity_file = annotation_file + 'identity_CelebA.txt'\n",
    "bbox_file = annotation_file + 'list_bbox_celeba.txt'\n",
    "\n",
    "# Train/test split variables\n",
    "random_seed = 123\n",
    "test_size = 0.2\n",
    "validation_size = 0.2\n",
    "\n",
    "identity_file = annotation_file + 'identity_CelebA.txt'\n",
    "bbox_file = annotation_file + 'list_bbox_celeba.txt'\n",
    "\n",
    "\n",
    "#Loading dataset metadata\n",
    "identity = pd.read_csv(identity_file, sep=\" \", header = None,names=['image', 'image_id'])\n",
    "bbox = pd.read_csv(bbox_file, delim_whitespace=True)\n",
    "\n",
    "\n",
    "#Filtering faces that appear at least 20 times\n",
    "labels_annot = pd.DataFrame(identity.image_id.value_counts(ascending=True)).query('image_id > 20').index.tolist()\n",
    "identity_filtered = identity[identity['image_id'].isin(labels_annot)]\n",
    "\n",
    "#Train/test split of the annotations\n",
    "imgs = identity_filtered['image']\n",
    "labels = identity_filtered['image_id']\n",
    "\n",
    "temp_imgs, test_imgs, _, test_labels = train_test_split(imgs, labels,\n",
    "                                               test_size = test_size,\n",
    "                                               random_state = random_seed,        \n",
    "                                               stratify = labels)\n",
    "train_imgs, valid_imgs, train_labels, valid_labels = train_test_split(temp_imgs, _,\n",
    "                                               test_size = validation_size/(1-test_size),\n",
    "                                               random_state = random_seed,        \n",
    "                                               stratify = _)\n",
    "\n",
    "#%% \n",
    "# Safe train/test split\n",
    "\n",
    "if not os.path.exists(export_file):\n",
    "    os.makedirs(export_file)\n",
    "\n",
    "if not os.path.exists(export_file + '/setting'):\n",
    "    os.makedirs(export_file + '/setting')\n",
    "\n",
    "if export_file != '':\n",
    "    train_imgs.to_csv(export_file + '/setting/train_imgs.csv', index = False)\n",
    "    valid_imgs.to_csv(export_file + '/setting/valid_imgs.csv', index = False)\n",
    "    test_imgs.to_csv(export_file + '/setting/test_imgs.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering training set - both images and labels as data frame.\n",
    "training_set = identity_filtered[identity_filtered['image'].isin(train_imgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting 100 labels having the most pictures - we gonna use only part of the training set.\n",
    "labs = list(train_labels.value_counts().head(1000).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting randomly 6 pictures per each label.\n",
    "random.seed(12496)\n",
    "pics = {i:[random.choices(list(training_set.loc[training_set['image_id'] == i,'image']), k = 10)] for i in labs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2820</td>\n",
       "      <td>001553.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2820</td>\n",
       "      <td>003568.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>008286.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2820</td>\n",
       "      <td>034769.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2820</td>\n",
       "      <td>043941.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>7233</td>\n",
       "      <td>009730.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7233</td>\n",
       "      <td>093995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>7233</td>\n",
       "      <td>118662.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>7233</td>\n",
       "      <td>019452.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7233</td>\n",
       "      <td>155608.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label       image\n",
       "0      2820  001553.jpg\n",
       "1      2820  003568.jpg\n",
       "2      2820  008286.jpg\n",
       "3      2820  034769.jpg\n",
       "4      2820  043941.jpg\n",
       "...     ...         ...\n",
       "9995   7233  009730.jpg\n",
       "9996   7233  093995.jpg\n",
       "9997   7233  118662.jpg\n",
       "9998   7233  019452.jpg\n",
       "9999   7233  155608.jpg\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining both filtered pictures and labels into a data frame.\n",
    "subset_df = pd.DataFrame(pics).transpose()\n",
    "subset_df.index = labs\n",
    "subset_df.columns = ['pics']\n",
    "subset_df[[f'pic_{i}' for i  in range(1,11)]] = pd.DataFrame(subset_df.pics.tolist(), index= subset_df.index)\n",
    "subset_df = subset_df.drop('pics',axis = 1)\n",
    "subset_df = subset_df.stack().reset_index().drop('level_1', axis=1).rename(columns = {'level_0':'label', 0: 'image'})\n",
    "subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the filtered labels and pictures.\n",
    "imgs_pn, labels_pn = subset_df['image'], subset_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the filtered subset of training set, we split this subset into training, validation and test set.\n",
    "temp_X, test_X, temp_Y, test_Y = train_test_split(imgs_pn, labels_pn,\n",
    "                    test_size = 0.2,random_state = random_seed, stratify = labels_pn)\n",
    "\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(temp_X, temp_Y,\n",
    "                    test_size = 0.25,random_state = random_seed, stratify = temp_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating paths for saving cropped images from the filtered subsets.\n",
    "if not os.path.exists('./cropped/train/'):\n",
    "    os.makedirs('./cropped/train/')\n",
    "\n",
    "if not os.path.exists('./cropped/valid/'):\n",
    "    os.makedirs('./cropped/valid/')\n",
    "\n",
    "if not os.path.exists('./cropped/test/'):\n",
    "    os.makedirs('./cropped/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropping(imgs, bboxes, sample):\n",
    "    \n",
    "    def face_crop(image_name, bbox_df):\n",
    "        # Loading Image\n",
    "        image_path = './data/Img/img_celeba/' + image_name\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        #Setting bounding box coordinates\n",
    "        startX = bbox_df[bbox_df['image_id'] == image_name]['x_1'].values[0]\n",
    "        startY = bbox_df[bbox_df['image_id'] == image_name]['y_1'].values[0]\n",
    "        endX = startX + bbox_df[bbox_df['image_id'] == image_name]['width'].values[0]\n",
    "        endY = startY + bbox_df[bbox_df['image_id'] == image_name]['height'].values[0]\n",
    "    \n",
    "        #Cropping\n",
    "        crop_img = img[startY:endY, startX:endX]\n",
    "        output_img = crop_img\n",
    "\n",
    "        output_img = cv2.resize(crop_img, (224, 224))\n",
    "\n",
    "        return output_img\n",
    "\n",
    "    #lists for storing cropped pictures and their names.\n",
    "    cropped_pics = []\n",
    "    pic_names = []\n",
    "\n",
    "    for pic in imgs:\n",
    "        crop_img = face_crop(pic, bboxes)\n",
    "        cropped_pics.append(crop_img)\n",
    "        pic_names.append(pic)\n",
    "\n",
    "        cv2.imwrite(f'./cropped/{sample.lower()}/{pic}', crop_img)\n",
    "\n",
    "    return cropped_pics, pic_names\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_train_X, train_X_names = cropping(train_X, bbox, 'train')\n",
    "cropped_valid_X, valid_X_names = cropping(valid_X, bbox, 'valid')\n",
    "cropped_test_X, test_X_names = cropping(test_X, bbox, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./cropped_numpys/'):\n",
    "    os.makedirs('./cropped_numpys/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 6000\n",
      "Number of validation instances: 2000\n",
      "Number of test instances: 2000\n"
     ]
    }
   ],
   "source": [
    "print('Number of training instances:',len(cropped_train_X))\n",
    "print('Number of validation instances:',len(cropped_valid_X))\n",
    "print('Number of test instances:',len(cropped_test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting list of images into arrays\n",
    "arr_train_X = np.array(cropped_train_X)\n",
    "arr_valid_X = np.array(cropped_valid_X)\n",
    "arr_test_X = np.array(cropped_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting list of labels into arrays\n",
    "arr_train_Y = np.array(train_Y)\n",
    "arr_valid_Y= np.array(valid_Y)\n",
    "arr_test_Y = np.array(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the numpy arrays of cropped pictures, pictures names and labels as numpy object for which will be used within the creation of pairs/triplets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npy ,sample in zip([arr_train_X, arr_valid_X, arr_test_X],  ['train','valid','test']):\n",
    "    with open(f'./cropped_numpys/cropped_{sample}_X.npy', 'wb') as f:\n",
    "        np.save(f, npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lst ,sample in zip([train_X_names, valid_X_names, test_X_names],  ['train','valid','test']):\n",
    "    with open(f'./cropped_numpys/cropped_{sample}_X_names.npy', 'wb') as f:\n",
    "        np.save(f, np.array(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab ,sample in zip([arr_train_Y, arr_valid_Y, arr_test_Y],  ['train','valid','test']):\n",
    "    with open(f'./cropped_numpys/cropped_{sample}_Y.npy', 'wb') as f:\n",
    "        np.save(f, lab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSE_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf7e70c757e4f60095653c44545a762e49c6e5d3353dc968e17e829e1045004e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
