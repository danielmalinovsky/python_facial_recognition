{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ngnpe\\anaconda3\\envs\\VSE_ML\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import src.proprietary_functions as src\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = './sample_data/Img/'\n",
    "annotation_file = './sample_data/Anno/'\n",
    "export_file = './export'\n",
    "\n",
    "identity_file = annotation_file + 'identity_CelebA.txt'\n",
    "bbox_file = annotation_file + 'list_bbox_celeba.txt'\n",
    "\n",
    "# Train/test split variables\n",
    "random_seed = 123\n",
    "test_size = 0.2\n",
    "validation_size = 0.2\n",
    "\n",
    "\n",
    "image_id_col = 'image_id'\n",
    "bbox_col_names = {\n",
    "    'x_start' : 'x_1',\n",
    "    'y_start' : 'y_1',\n",
    "    'width' : 'width',\n",
    "    'height' : 'height',\n",
    "    'x_end' : '',\n",
    "    'y_end' : ''}\n",
    "\n",
    "identity_file = annotation_file + 'identity_CelebA.txt'\n",
    "bbox_file = annotation_file + 'list_bbox_celeba.txt'\n",
    "\n",
    "\n",
    "\n",
    "# Loading dataset metadata\n",
    "identity = pd.read_csv(identity_file, sep=\" \", header = None,names=['image', 'image_id'])\n",
    "bbox = pd.read_csv(bbox_file, delim_whitespace=True)\n",
    "\n",
    "\n",
    "#%% Filtering faces that appear at least 20 times\n",
    "labels_annot = pd.DataFrame(identity.image_id.value_counts(ascending=True)).query('image_id > 20').index.tolist()\n",
    "identity_filtered = identity[identity['image_id'].isin(labels_annot)]\n",
    "\n",
    "#%% [SPRINT 2] Train/test split of the annotations\n",
    "imgs = identity_filtered['image']\n",
    "labels = identity_filtered['image_id']\n",
    "\n",
    "temp_imgs, test_imgs, _, test_labels = train_test_split(imgs, labels,\n",
    "                                               test_size = test_size,\n",
    "                                               random_state = random_seed,        \n",
    "                                               stratify = labels)\n",
    "train_imgs, valid_imgs, train_labels, valid_labels = train_test_split(temp_imgs, _,\n",
    "                                               test_size = validation_size/(1-test_size),\n",
    "                                               random_state = random_seed,        \n",
    "                                               stratify = _)\n",
    "\n",
    "#%% \n",
    "# Safe train/test split\n",
    "\n",
    "if not os.path.exists(export_file):\n",
    "    os.makedirs(export_file)\n",
    "\n",
    "if not os.path.exists(export_file + '/setting'):\n",
    "    os.makedirs(export_file + '/setting')\n",
    "\n",
    "if export_file != '':\n",
    "    train_imgs.to_csv(export_file + '/setting/train_imgs.csv', index = False)\n",
    "    valid_imgs.to_csv(export_file + '/setting/valid_imgs.csv', index = False)\n",
    "    test_imgs.to_csv(export_file + '/setting/test_imgs.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering training set - both images and labels as data frame.\n",
    "training_set = identity_filtered[identity_filtered['image'].isin(train_imgs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting 100 labels having the most pictures - we gonna use only part of the training set.\n",
    "labs = list(train_labels.value_counts().head(1000).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting randomly 6 pictures per each label.\n",
    "random.seed(12496)\n",
    "pics = {i:[random.choices(list(training_set.loc[training_set['image_id'] == i,'image']), k = 10)] for i in labs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2820</td>\n",
       "      <td>001553.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2820</td>\n",
       "      <td>003568.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>008286.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2820</td>\n",
       "      <td>034769.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2820</td>\n",
       "      <td>043941.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>7233</td>\n",
       "      <td>009730.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7233</td>\n",
       "      <td>093995.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>7233</td>\n",
       "      <td>118662.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>7233</td>\n",
       "      <td>019452.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7233</td>\n",
       "      <td>155608.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label       image\n",
       "0      2820  001553.jpg\n",
       "1      2820  003568.jpg\n",
       "2      2820  008286.jpg\n",
       "3      2820  034769.jpg\n",
       "4      2820  043941.jpg\n",
       "...     ...         ...\n",
       "9995   7233  009730.jpg\n",
       "9996   7233  093995.jpg\n",
       "9997   7233  118662.jpg\n",
       "9998   7233  019452.jpg\n",
       "9999   7233  155608.jpg\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#combining both filtered pictures and labels into a data frame.\n",
    "subset_df = pd.DataFrame(pics).transpose()\n",
    "subset_df.index = labs\n",
    "subset_df.columns = ['pics']\n",
    "subset_df[[f'pic_{i}' for i  in range(1,11)]] = pd.DataFrame(subset_df.pics.tolist(), index= subset_df.index)\n",
    "subset_df = subset_df.drop('pics',axis = 1)\n",
    "subset_df = subset_df.stack().reset_index().drop('level_1', axis=1).rename(columns = {'level_0':'label', 0: 'image'})\n",
    "subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the filtered labels and pictures.\n",
    "imgs_pn, labels_pn = subset_df['image'], subset_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the filtered subset of training set, we split this subset into training, validation and test set.\n",
    "temp_X, test_X, temp_Y, test_Y = train_test_split(imgs_pn, labels_pn,\n",
    "                    test_size = 0.2,random_state = random_seed, stratify = labels_pn)\n",
    "\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(temp_X, temp_Y,\n",
    "                    test_size = 0.25,random_state = random_seed, stratify = temp_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating paths for saving cropped images from the filtered subsets.\n",
    "if not os.path.exists('./cropped/train/'):\n",
    "    os.makedirs('./cropped/train/')\n",
    "\n",
    "if not os.path.exists('./cropped/valid/'):\n",
    "    os.makedirs('./cropped/valid/')\n",
    "\n",
    "if not os.path.exists('./cropped/test/'):\n",
    "    os.makedirs('./cropped/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropping(imgs, bboxes, sample):\n",
    "    \n",
    "    def face_crop(image_name, bbox_df):\n",
    "        # Loading Image\n",
    "        image_path = './data/Img/img_celeba/' + image_name\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "    # Setting bounding box coordinates\n",
    "        startX = bbox_df[bbox_df['image_id'] == image_name]['x_1'].values[0]\n",
    "        startY = bbox_df[bbox_df['image_id'] == image_name]['y_1'].values[0]\n",
    "        endX = startX + bbox_df[bbox_df['image_id'] == image_name]['width'].values[0]\n",
    "        endY = startY + bbox_df[bbox_df['image_id'] == image_name]['height'].values[0]\n",
    "    \n",
    "    #Cropping and saving boounding box\n",
    "        crop_img = img[startY:endY, startX:endX]\n",
    "        output_img = crop_img\n",
    "\n",
    "        output_img = cv2.resize(crop_img, (224, 224))\n",
    "\n",
    "        return output_img\n",
    "\n",
    "    cropped_pics = []\n",
    "    pic_names = []\n",
    "\n",
    "    for pic in imgs:\n",
    "        crop_img = face_crop(pic, bboxes)\n",
    "        cropped_pics.append(crop_img)\n",
    "        pic_names.append(pic)\n",
    "\n",
    "        cv2.imwrite(f'./cropped/{sample.lower()}/{pic}', crop_img)\n",
    "\n",
    "    return cropped_pics, pic_names\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_train_X, train_X_names = cropping(train_X, bbox, 'train')\n",
    "cropped_valid_X, valid_X_names = cropping(valid_X, bbox, 'valid')\n",
    "cropped_test_X, test_X_names = cropping(test_X, bbox, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./cropped_numpys/'):\n",
    "    os.makedirs('./cropped_numpys/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances: 6000\n",
      "Number of validation instances: 2000\n",
      "Number of test instances: 2000\n"
     ]
    }
   ],
   "source": [
    "print('Number of training instances:',len(cropped_train_X))\n",
    "print('Number of validation instances:',len(cropped_valid_X))\n",
    "print('Number of test instances:',len(cropped_test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting list of images into arrays\n",
    "arr_train_X = np.array(cropped_train_X)\n",
    "arr_valid_X = np.array(cropped_valid_X)\n",
    "arr_test_X = np.array(cropped_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting list of labels into arrays\n",
    "arr_train_Y = np.array(train_Y)\n",
    "arr_valid_Y= np.array(valid_Y)\n",
    "arr_test_Y = np.array(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npy ,sample in zip([arr_train_X, arr_valid_X, arr_test_X],  ['train','valid','test']):\n",
    "    with open(f'./cropped_numpys/cropped_{sample}_X.npy', 'wb') as f:\n",
    "        np.save(f, npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lst ,sample in zip([train_X_names, valid_X_names, test_X_names],  ['train','valid','test']):\n",
    "    with open(f'./cropped_numpys/cropped_{sample}_X_names.npy', 'wb') as f:\n",
    "        np.save(f, np.array(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lab ,sample in zip([arr_train_Y, arr_valid_Y, arr_test_Y],  ['train','valid','test']):\n",
    "    with open(f'./cropped_numpys/cropped_{sample}_Y.npy', 'wb') as f:\n",
    "        np.save(f, lab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VSE_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf7e70c757e4f60095653c44545a762e49c6e5d3353dc968e17e829e1045004e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
