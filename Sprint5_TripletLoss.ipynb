{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import src.proprietary_functions as src\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of samples strings\n",
    "list_samples = ['train','valid','test']\n",
    "#dictionary for storing cropped images, image names and labels\n",
    "arr_dicts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing numpy objects of cropped images\n",
    "for sampl in list_samples:\n",
    "    with open(f'./cropped_numpys/cropped_{sampl}_X.npy', 'rb') as f:\n",
    "        arr_dicts[f'arr_{sampl}_X']  = np.load(f)\n",
    "\n",
    "arr_train_X = arr_dicts['arr_train_X']\n",
    "arr_valid_X = arr_dicts['arr_valid_X']\n",
    "arr_test_X = arr_dicts['arr_test_X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing numpy objects of image names\n",
    "for sampl in list_samples:\n",
    "    with open(f'./cropped_numpys/cropped_{sampl}_X_names.npy', 'rb') as f:\n",
    "        arr_dicts[f'{sampl}_X_names']  = np.load(f)\n",
    "\n",
    "train_X_names = arr_dicts['train_X_names']\n",
    "valid_X_names = arr_dicts['valid_X_names']\n",
    "test_X_names = arr_dicts['test_X_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing numpy objects of labels\n",
    "for sampl in list_samples:\n",
    "    with open(f'./cropped_numpys/cropped_{sampl}_Y.npy', 'rb') as f:\n",
    "        arr_dicts[f'arr_{sampl}_Y']  = np.load(f)\n",
    "\n",
    "arr_train_Y = arr_dicts['arr_train_Y']\n",
    "arr_valid_Y = arr_dicts['arr_valid_Y']\n",
    "arr_test_Y = arr_dicts['arr_test_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for creation of triplets\n",
    "def\tmake_triplets(images, labels, image_names):\n",
    "\n",
    "\ttripletImages = []\n",
    "\ttripletImagesNames = []\n",
    "\tuniqueClasses = np.unique(labels)\n",
    "\n",
    "\tdict_idx = {i:np.where(labels == i)[0] for i in uniqueClasses}\n",
    "\n",
    "\tfor idxA in range(len(images)):\n",
    "\n",
    "\t\t#current image\n",
    "\t\tcurrentImage = images[idxA]\n",
    "\t\tlabel = labels[idxA]\n",
    "\t\tcurrentImage_name = image_names[idxA]\n",
    "\n",
    "\t\t#positive image\n",
    "\t\tidxB = np.random.choice(dict_idx[label])\n",
    "\t\tposImage = images[idxB]\n",
    "\t\tposImage_name = image_names[idxB]\n",
    "\n",
    "\t\t#negative image\n",
    "\t\tnegLab = np.random.choice([i for i in dict_idx.keys() if i != label])\n",
    "\t\tnegIdx = np.random.choice(dict_idx[negLab])\n",
    "\t\tnegImage = images[negIdx]\n",
    "\t\tnegImage_name = image_names[negIdx]\n",
    "        \n",
    "\t\t#saving the triplets of images and image names\n",
    "\t\ttripletImages.append([currentImage, posImage, negImage])\n",
    "\t\ttripletImagesNames.append([currentImage_name, posImage_name, negImage_name])\n",
    "\n",
    "\treturn (np.array(tripletImages), np.array(tripletImagesNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_triplets, train_triplets_names= make_triplets(arr_train_X, arr_train_Y, train_X_names)\n",
    "valid_X_triplets, valid_triplets_names = make_triplets(arr_valid_X, arr_valid_Y, valid_X_names)\n",
    "test_X_triplets, test_triplets_names = make_triplets(arr_test_X, arr_test_Y, test_X_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./triplet_numpys/'):\n",
    "    os.makedirs('./triplet_numpys/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_triplets = {'train': {'triplet_imgs': train_X_triplets, 'triplet_imgs_names':train_triplets_names},\n",
    "                'valid': {'triplet_imgs': valid_X_triplets,'triplet_imgs_names':valid_triplets_names},\n",
    "                'test': {'triplet_imgs': test_X_triplets, 'triplet_imgs_names':test_triplets_names}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the triplets of images and image names as numpy objects.\n",
    "for sampl in dict_triplets.keys():\n",
    "    for n in dict_triplets[sampl].keys():\n",
    "       with open(f'./triplet_numpys/{sampl}_{n}.npy', 'wb') as f:\n",
    "            np.save(f, dict_triplets[sampl][n])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN model building with triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 13:26:16.672090: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "def initialize_base_network():\n",
    "    input = Input(shape=(224,224,3))\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(120, activation='relu')(x)\n",
    "    return Model(inputs=input, outputs=x)\n",
    "\n",
    "embedding = initialize_base_network()\n",
    "tf.keras.utils.plot_model(embedding, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet(tf.keras.layers.Layer):\n",
    "    # set the backbone model in constructor\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, feat):\n",
    "        # get feature vectors from anchor\n",
    "        feats = self.model(feat[0])\n",
    "        # from positive image\n",
    "        pfeats = self.model(feat[1])\n",
    "        # and from negative image\n",
    "        nfeats = self.model(feat[2])\n",
    "        # concatenate vectors to a matrix\n",
    "        result = tf.stack([feats, pfeats, nfeats])\n",
    "        return result\n",
    "\n",
    "class TripletLoss(tf.keras.layers.Layer):\n",
    "    # margin is settable hyperparameter in constructor\n",
    "    def __init__(self, margin):\n",
    "        self.margin = margin\n",
    "        super().__init__()\n",
    "        \n",
    "    # function calculating distance between features\n",
    "    def distance(self, x, y):\n",
    "        sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "        return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "    def call(self, features):\n",
    "        # get anchor-positive distance\n",
    "        pos = self.distance(features[0], features[1])\n",
    "        # anchor-negative distance\n",
    "        neg = self.distance(features[0], features[2])\n",
    "        # difference between anchor positive and anchor negative distances\n",
    "        loss = pos - neg\n",
    "        # get overall loss\n",
    "        return tf.maximum(loss + self.margin, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchor branch\n",
    "image_input = Input(shape=(224,224,3), name='image_input')\n",
    "# positive image branch\n",
    "positive_input = Input(shape=(224,224,3), name='positive_input')\n",
    "# negative image branch\n",
    "negative_input = Input(shape=(224,224,3), name='negative_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(abs(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese = SiameseNet(embedding)([image_input, positive_input, negative_input])\n",
    "loss = TripletLoss(margin=1.0)(siamese)\n",
    "model = Model(inputs=[image_input, positive_input, negative_input], outputs=loss)\n",
    "model.compile(optimizer ='adam', loss = identity_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "188/188 [==============================] - 33s 164ms/step - loss: 256.0246 - val_loss: 1.5270\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 24s 126ms/step - loss: 5.0000e-04 - val_loss: 1.5270\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 26s 135ms/step - loss: 5.0000e-04 - val_loss: 1.5270\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 28s 150ms/step - loss: 5.0000e-04 - val_loss: 1.5270\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 28s 145ms/step - loss: 5.0000e-04 - val_loss: 1.5270\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 27s 143ms/step - loss: 5.0000e-04 - val_loss: 1.5270\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 30s 158ms/step - loss: 5.0000e-04 - val_loss: 1.5270\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 29s 155ms/step - loss: 5.0000e-04 - val_loss: 1.5270\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 27s 141ms/step - loss: 5.0000e-04 - val_loss: 1.5270\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 27s 140ms/step - loss: 5.0000e-04 - val_loss: 1.5270\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train_X_triplets[:,0], train_X_triplets[:,1], train_X_triplets[:,2]], np.ones(train_X_triplets.shape[0]),\n",
    "                verbose=1,\n",
    "            validation_data=([valid_X_triplets[:,0], valid_X_triplets[:,1], valid_X_triplets[:,2]], np.ones(valid_X_triplets.shape[0])),\n",
    "            epochs=10)\n",
    "            #epochs = 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a3093573-a704-4d2d-9e39-b2f2ba2f80db/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model_file = \"./triplets.sav\"\n",
    "pickle.dump(model, open(model_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function creating pairs\n",
    "def\tmake_pairs(images, labels):\n",
    "\n",
    "\tpairImages = []\n",
    "\tpairLabels = []\n",
    "\tuniqueClasses = np.unique(labels)\n",
    "\n",
    "\tdict_idx = {i:np.where(labels == i)[0] for i in uniqueClasses}\n",
    "\n",
    "\tfor idxA in range(len(images)):\n",
    "\t\tcurrentImage = images[idxA]\n",
    "\t\tlabel = labels[idxA]\n",
    "\n",
    "\t\t#positive pair\n",
    "\t\tidxB = np.random.choice(dict_idx[label])\n",
    "\t\tposImage = images[idxB]\n",
    "\t\tpairImages.append([currentImage, posImage])\n",
    "\n",
    "\t\tpairLabels.append([1])\n",
    "\n",
    "\t\t#negative pair\n",
    "\t\tnegLab = np.random.choice([i for i in dict_idx.keys() if i != label])\n",
    "\t\tnegIdx = np.random.choice(dict_idx[negLab])\n",
    "\t\tnegImage = images[negIdx]\n",
    "\t\tpairImages.append([currentImage, negImage])\n",
    "\n",
    "\t\tpairLabels.append([0])\n",
    "\n",
    "\treturn (np.array(pairImages),np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairTest, labelTest = make_pairs(arr_test_X, arr_test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_pair = pairTest[:,0]\n",
    "right_pair = pairTest[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 2s 16ms/step\n",
      "125/125 [==============================] - 2s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "left_pair_pred = embedding.predict(left_pair)\n",
    "right_pair_pred = embedding.predict(right_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(left_pred, right_pred, y_true):\n",
    "    y_pred = np.linalg.norm(left_pred - right_pred, axis=1)\n",
    "#     # 1 for the same - distance is smaller than 3.0, 0 for the different\n",
    "    pred = y_pred < 7.0\n",
    "    return np.mean(pred == y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = compute_accuracy(left_pair_pred, right_pair_pred, labelTest)\n",
    "print(f'Test accuracy: {test_accuracy*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('vseML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b16878dc9fba3fc1f29102bb5a5d5908ed8d93b9d265a120b4075722889fce6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
